{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 一、数据分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale = pd.read_csv('sales_train_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "      <td>30490.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.070220</td>\n",
       "      <td>1.041292</td>\n",
       "      <td>0.780026</td>\n",
       "      <td>0.833454</td>\n",
       "      <td>0.627944</td>\n",
       "      <td>0.958052</td>\n",
       "      <td>0.918662</td>\n",
       "      <td>1.244080</td>\n",
       "      <td>1.073663</td>\n",
       "      <td>0.838701</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370581</td>\n",
       "      <td>1.586159</td>\n",
       "      <td>1.693670</td>\n",
       "      <td>1.248245</td>\n",
       "      <td>1.232207</td>\n",
       "      <td>1.159167</td>\n",
       "      <td>1.149000</td>\n",
       "      <td>1.328862</td>\n",
       "      <td>1.605838</td>\n",
       "      <td>1.633158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.126689</td>\n",
       "      <td>5.365468</td>\n",
       "      <td>3.667454</td>\n",
       "      <td>4.415141</td>\n",
       "      <td>3.379344</td>\n",
       "      <td>4.785947</td>\n",
       "      <td>5.059495</td>\n",
       "      <td>6.617729</td>\n",
       "      <td>5.917204</td>\n",
       "      <td>4.206199</td>\n",
       "      <td>...</td>\n",
       "      <td>3.740017</td>\n",
       "      <td>4.097191</td>\n",
       "      <td>4.359809</td>\n",
       "      <td>3.276925</td>\n",
       "      <td>3.125471</td>\n",
       "      <td>2.876026</td>\n",
       "      <td>2.950364</td>\n",
       "      <td>3.358012</td>\n",
       "      <td>4.089422</td>\n",
       "      <td>3.812248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>360.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>353.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                d_1           d_2           d_3           d_4           d_5  \\\n",
       "count  30490.000000  30490.000000  30490.000000  30490.000000  30490.000000   \n",
       "mean       1.070220      1.041292      0.780026      0.833454      0.627944   \n",
       "std        5.126689      5.365468      3.667454      4.415141      3.379344   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      360.000000    436.000000    207.000000    323.000000    296.000000   \n",
       "\n",
       "                d_6           d_7           d_8           d_9          d_10  \\\n",
       "count  30490.000000  30490.000000  30490.000000  30490.000000  30490.000000   \n",
       "mean       0.958052      0.918662      1.244080      1.073663      0.838701   \n",
       "std        4.785947      5.059495      6.617729      5.917204      4.206199   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      314.000000    316.000000    370.000000    385.000000    353.000000   \n",
       "\n",
       "           ...             d_1904        d_1905        d_1906        d_1907  \\\n",
       "count      ...       30490.000000  30490.000000  30490.000000  30490.000000   \n",
       "mean       ...           1.370581      1.586159      1.693670      1.248245   \n",
       "std        ...           3.740017      4.097191      4.359809      3.276925   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           1.000000      2.000000      2.000000      1.000000   \n",
       "max        ...         129.000000    160.000000    204.000000     98.000000   \n",
       "\n",
       "             d_1908        d_1909        d_1910        d_1911        d_1912  \\\n",
       "count  30490.000000  30490.000000  30490.000000  30490.000000  30490.000000   \n",
       "mean       1.232207      1.159167      1.149000      1.328862      1.605838   \n",
       "std        3.125471      2.876026      2.950364      3.358012      4.089422   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000      1.000000      1.000000      2.000000   \n",
       "max      100.000000     88.000000     77.000000    141.000000    171.000000   \n",
       "\n",
       "             d_1913  \n",
       "count  30490.000000  \n",
       "mean       1.633158  \n",
       "std        3.812248  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        2.000000  \n",
       "max      130.000000  \n",
       "\n",
       "[8 rows x 1913 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1716026, 31)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_data = sale[[f'd_{day}' for day in range(1,1914)]]\n",
    "total_sum = np.sum(day_data,axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10e693240>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f56d312c83be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.hist(total_sum,bins= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 二、特征工程\n",
    "\n",
    "选定机器学习的建模方案，核心思想是对时间序列抽取窗口特征\n",
    "\n",
    "抽取窗口特征：\n",
    "\n",
    "- 前7天\n",
    "- 前28天\n",
    "- 前7天均值\n",
    "- 前28天均值\n",
    "\n",
    "关联其他维度信息\n",
    "\n",
    "- 日期\n",
    "- 价格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import lightgbm as lgb\n",
    "from  datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data(train_start=750,test_start=1800,end=500,is_train=True,name=''):\n",
    "    # 基本参数\n",
    "    PRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float32\" }\n",
    "    CAL_DTYPES={\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n",
    "            \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n",
    "            \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }\n",
    "\n",
    "    start_day = train_start if is_train else test_start\n",
    "    numcols = [f\"d_{day}\" for day in range(start_day,end+1)]\n",
    "    catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "    SALE_DTYPES = {numcol:\"float32\" for numcol in numcols} \n",
    "    SALE_DTYPES.update({col: \"category\" for col in catcols if col != \"id\"})\n",
    "\n",
    "    # 加载price数据\n",
    "    price_data = pd.read_csv('sell_prices.csv',dtype=PRICE_DTYPES)\n",
    "    price_data = price_data.loc[price_data.store_id == name,:]\n",
    "    # 加载cal数据\n",
    "    cal_data = pd.read_csv('calendar.csv',dtype=CAL_DTYPES)\n",
    "    # 加载sale数据\n",
    "    sale_data = pd.read_csv('sales_train_validation.csv',dtype=SALE_DTYPES,usecols=catcols+numcols)\n",
    "    sale_data = sale_data.loc[sale_data.store_id == name,:]\n",
    "\n",
    "\n",
    "    # 类别标签转换\n",
    "    for col, col_dtype in PRICE_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            price_data[col] = price_data[col].cat.codes.astype(\"int16\")\n",
    "            price_data[col] -= price_data[col].min()\n",
    "\n",
    "    cal_data[\"date\"] = pd.to_datetime(cal_data[\"date\"])\n",
    "    for col, col_dtype in CAL_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            cal_data[col] = cal_data[col].cat.codes.astype(\"int16\")\n",
    "            cal_data[col] -= cal_data[col].min()\n",
    "\n",
    "\n",
    "    for col in catcols:\n",
    "        if col != \"id\":\n",
    "            sale_data[col] = sale_data[col].cat.codes.astype(\"int16\")\n",
    "            sale_data[col] -= sale_data[col].min()\n",
    "\n",
    "    # 注意提交格式里有一部分为空\n",
    "    if not is_train:\n",
    "        for day in range(end+1, end+ 2*28 +1):\n",
    "            sale_data[f\"d_{day}\"] = np.nan\n",
    "\n",
    "    sale_data = pd.melt(sale_data,\n",
    "            id_vars = catcols,\n",
    "            value_vars = [col for col in sale_data.columns if col.startswith(\"d_\")],\n",
    "            var_name = \"d\",\n",
    "            value_name = \"sales\")\n",
    "    sale_data = sale_data.merge(cal_data, on= \"d\", copy = False)\n",
    "    sale_data = sale_data.merge(price_data, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "    return sale_data\n",
    "\n",
    "\n",
    "def create_feature(sale_data, is_train=True, day=None):\n",
    "    # 可以在这里加入更多的特征抽取方法\n",
    "    # 获取7天前的数据，28天前的数据\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags ]\n",
    "\n",
    "    # 如果是测试集只需要计算一天的特征，减少计算量\n",
    "    # 注意训练集和测试集特征生成要一致\n",
    "    if is_train:\n",
    "        for lag, lag_col in zip(lags, lag_cols):\n",
    "            sale_data[lag_col] = sale_data[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
    "    else:\n",
    "        for lag, lag_col in zip(lags, lag_cols):\n",
    "            sale_data.loc[sale_data.date == day, lag_col] = sale_data.loc[sale_data.date ==day-timedelta(days=lag), 'sales'].values  \n",
    "\n",
    "\n",
    "    # 将获取7天前的数据，28天前的数据做移动平均\n",
    "    wins = [7, 28]\n",
    "\n",
    "    if is_train:\n",
    "        for win in wins :\n",
    "            for lag,lag_col in zip(lags, lag_cols):\n",
    "                sale_data[f\"rmean_{lag}_{win}\"] = sale_data[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean())\n",
    "    else:\n",
    "        for win in wins:\n",
    "            for lag in lags:\n",
    "                df_window = sale_data[(sale_data.date <= day-timedelta(days=lag)) & (sale_data.date > day-timedelta(days=lag+win))]\n",
    "                df_window_grouped = df_window.groupby(\"id\").agg({'sales':'mean'}).reindex(sale_data.loc[sale_data.date==day,'id'])\n",
    "                sale_data.loc[sale_data.date == day,f\"rmean_{lag}_{win}\"] = df_window_grouped.sales.values   \n",
    "\n",
    "    # 处理时间特征\n",
    "    # 有的时间特征没有，通过datetime的方法自动生成\n",
    "    date_features = {\n",
    "            \"wday\": \"weekday\",\n",
    "            \"week\": \"weekofyear\",\n",
    "            \"month\": \"month\",\n",
    "            \"quarter\": \"quarter\",\n",
    "            \"year\": \"year\",\n",
    "            \"mday\": \"day\",\n",
    "        }\n",
    "\n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in sale_data.columns:\n",
    "            sale_data[date_feat_name] = sale_data[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            sale_data[date_feat_name] = getattr(sale_data[\"date\"].dt, date_feat_func).astype(\"int16\")\n",
    "    return sale_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ensemble_NoWeight(train_cols,m_lgb,name):\n",
    "    date = datetime(2016,4, 25)#训练集截至时间 1914  #datetime(2016,3, 28) # d_1886\n",
    "    # alphas = [1.035, 1.03, 1.025, 1.02]\n",
    "    # alphas = [1.028, 1.023, 1.018]\n",
    "    #alphas = [1.035, 1.03, 1.025]\n",
    "    #weights = [1/len(alphas)]*len(alphas)\n",
    "    sub = 0.\n",
    "\n",
    "    test_data = create_train_data(test_start=1800,end=1913,is_train=False,name=name)\n",
    "    #print(test_data.columns)\n",
    "\n",
    "    #for icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n",
    "\n",
    "    test_data_c = test_data.copy()\n",
    "    cols = [f\"F{i}\" for i in range(1,29)]\n",
    "\n",
    "\n",
    "    for i in range(0, 28):\n",
    "        day = date + timedelta(days=i)\n",
    "        #print(i, day)\n",
    "        tst = test_data_c[(test_data_c.date >= day - timedelta(days=60)) & (test_data_c.date <= day)].copy()\n",
    "        tst = create_feature(tst,is_train=False, day=day)\n",
    "        tst = tst.loc[tst.date == day , train_cols]\n",
    "\n",
    "        test_data_c.loc[test_data_c.date == day, \"sales\"] = m_lgb.predict(tst)\n",
    "\n",
    "    # 改为提交数据的格式\n",
    "    test_sub = test_data_c.loc[test_data_c.date >= date, [\"id\", \"sales\"]].copy()\n",
    "    test_sub[\"F\"] = [f\"F{rank}\" for rank in test_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "    test_sub = test_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][cols].reset_index()\n",
    "    test_sub.fillna(0., inplace = True)\n",
    "    test_sub.sort_values(\"id\", inplace = True)\n",
    "    test_sub.reset_index(drop=True, inplace = True)\n",
    "    test_sub.to_csv(f\"{name}_sub_NoWeight.csv\",index=False)\n",
    "#     if icount == 0 :\n",
    "#         sub = test_sub\n",
    "#         sub[cols] *= weight\n",
    "#     else:\n",
    "#         sub[cols] += test_sub[cols]*weight\n",
    "#     #print(icount, alpha, weight)\n",
    "    \n",
    "#     sub2 = sub.copy()\n",
    "#     # 把大于28天后的validation替换成evaluation\n",
    "#     sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "#     sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "#     sub.to_csv(f\"{name}_sub.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data,valid_data):\n",
    "    params = {\n",
    "        \"objective\" : \"tweedie\",\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.075,\n",
    "        \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.75,\n",
    "        \"bagging_freq\" : 1,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "        \"metric\": [\"rmse\"],\n",
    "        \"nthread\": 8,\n",
    "        \"tweedie_variance_power\":1.2,\n",
    "    'verbosity': 1,\n",
    "    'num_iterations' : 2200,\n",
    "    'num_leaves': 128,\n",
    "    \"min_data_in_leaf\": 104,\n",
    "    }\n",
    "\n",
    "    m_lgb = lgb.train(params, train_data, valid_sets = [valid_data], verbose_eval=100)\n",
    "\n",
    "    return m_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1',\n",
    "       'WI_2', 'WI_3']\n",
    "starDay = [300]*10#[700,700,700,700,700,700,700,700,700,700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = ['event_name_2', 'event_type_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA_1开始啦---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning:\n",
      "\n",
      "Found `num_iterations` in params. Will use it instead of argument\n",
      "\n",
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1382: UserWarning:\n",
      "\n",
      "Using categorical_feature in Dataset.\n",
      "\n",
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1117: UserWarning:\n",
      "\n",
      "Overriding the parameters from Reference Dataset.\n",
      "\n",
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:929: UserWarning:\n",
      "\n",
      "categorical_column in param dict is overridden.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.42853\n",
      "[200]\tvalid_0's rmse: 2.30628\n",
      "[300]\tvalid_0's rmse: 2.24488\n",
      "[400]\tvalid_0's rmse: 2.20648\n",
      "[500]\tvalid_0's rmse: 2.17267\n",
      "[600]\tvalid_0's rmse: 2.14749\n",
      "[700]\tvalid_0's rmse: 2.12589\n",
      "[800]\tvalid_0's rmse: 2.10545\n",
      "[900]\tvalid_0's rmse: 2.09338\n",
      "[1000]\tvalid_0's rmse: 2.07863\n",
      "[1100]\tvalid_0's rmse: 2.0631\n",
      "[1200]\tvalid_0's rmse: 2.05085\n",
      "[1300]\tvalid_0's rmse: 2.03821\n",
      "[1400]\tvalid_0's rmse: 2.0251\n",
      "[1500]\tvalid_0's rmse: 2.01164\n",
      "[1600]\tvalid_0's rmse: 2.00329\n",
      "[1700]\tvalid_0's rmse: 1.98683\n",
      "[1800]\tvalid_0's rmse: 1.97816\n",
      "[1900]\tvalid_0's rmse: 1.96698\n",
      "[2000]\tvalid_0's rmse: 1.95626\n",
      "[2100]\tvalid_0's rmse: 1.94556\n",
      "[2200]\tvalid_0's rmse: 1.93638\n",
      "CA_2开始啦---------------------------------------\n",
      "[100]\tvalid_0's rmse: 1.89053\n",
      "[200]\tvalid_0's rmse: 1.85522\n",
      "[300]\tvalid_0's rmse: 1.82778\n",
      "[400]\tvalid_0's rmse: 1.80421\n",
      "[500]\tvalid_0's rmse: 1.78243\n",
      "[600]\tvalid_0's rmse: 1.76608\n",
      "[700]\tvalid_0's rmse: 1.75079\n",
      "[800]\tvalid_0's rmse: 1.73832\n",
      "[900]\tvalid_0's rmse: 1.72774\n",
      "[1000]\tvalid_0's rmse: 1.7161\n",
      "[1100]\tvalid_0's rmse: 1.70476\n",
      "[1200]\tvalid_0's rmse: 1.6963\n",
      "[1300]\tvalid_0's rmse: 1.68727\n",
      "[1400]\tvalid_0's rmse: 1.67948\n",
      "[1500]\tvalid_0's rmse: 1.67179\n",
      "[1600]\tvalid_0's rmse: 1.66375\n",
      "[1700]\tvalid_0's rmse: 1.65514\n",
      "[1800]\tvalid_0's rmse: 1.64794\n",
      "[1900]\tvalid_0's rmse: 1.64157\n",
      "[2000]\tvalid_0's rmse: 1.63451\n",
      "[2100]\tvalid_0's rmse: 1.62861\n",
      "[2200]\tvalid_0's rmse: 1.62144\n",
      "CA_3开始啦---------------------------------------\n",
      "[100]\tvalid_0's rmse: 3.25273\n",
      "[200]\tvalid_0's rmse: 3.13793\n",
      "[300]\tvalid_0's rmse: 3.05486\n",
      "[400]\tvalid_0's rmse: 2.99904\n",
      "[500]\tvalid_0's rmse: 2.95313\n",
      "[600]\tvalid_0's rmse: 2.9229\n",
      "[700]\tvalid_0's rmse: 2.88466\n",
      "[800]\tvalid_0's rmse: 2.85282\n",
      "[900]\tvalid_0's rmse: 2.82581\n",
      "[1000]\tvalid_0's rmse: 2.79944\n",
      "[1100]\tvalid_0's rmse: 2.77685\n",
      "[1200]\tvalid_0's rmse: 2.75902\n",
      "[1300]\tvalid_0's rmse: 2.74445\n",
      "[1400]\tvalid_0's rmse: 2.72763\n",
      "[1500]\tvalid_0's rmse: 2.71152\n",
      "[1600]\tvalid_0's rmse: 2.69276\n",
      "[1700]\tvalid_0's rmse: 2.67811\n",
      "[1800]\tvalid_0's rmse: 2.66069\n",
      "[1900]\tvalid_0's rmse: 2.64706\n",
      "[2000]\tvalid_0's rmse: 2.63232\n",
      "[2100]\tvalid_0's rmse: 2.62042\n",
      "[2200]\tvalid_0's rmse: 2.60947\n",
      "CA_4开始啦---------------------------------------\n",
      "[100]\tvalid_0's rmse: 1.50799\n",
      "[200]\tvalid_0's rmse: 1.46649\n",
      "[300]\tvalid_0's rmse: 1.43765\n",
      "[400]\tvalid_0's rmse: 1.41667\n",
      "[500]\tvalid_0's rmse: 1.40068\n",
      "[600]\tvalid_0's rmse: 1.38988\n",
      "[700]\tvalid_0's rmse: 1.37571\n",
      "[800]\tvalid_0's rmse: 1.36758\n",
      "[900]\tvalid_0's rmse: 1.35924\n",
      "[1000]\tvalid_0's rmse: 1.35073\n",
      "[1100]\tvalid_0's rmse: 1.34312\n",
      "[1200]\tvalid_0's rmse: 1.33834\n",
      "[1300]\tvalid_0's rmse: 1.33154\n",
      "[1400]\tvalid_0's rmse: 1.32349\n",
      "[1500]\tvalid_0's rmse: 1.31835\n",
      "[1600]\tvalid_0's rmse: 1.31024\n",
      "[1700]\tvalid_0's rmse: 1.30422\n",
      "[1800]\tvalid_0's rmse: 1.30012\n",
      "[1900]\tvalid_0's rmse: 1.29581\n",
      "[2000]\tvalid_0's rmse: 1.29214\n",
      "[2100]\tvalid_0's rmse: 1.28569\n",
      "[2200]\tvalid_0's rmse: 1.27816\n",
      "TX_1开始啦---------------------------------------\n",
      "[100]\tvalid_0's rmse: 2.04819\n",
      "[200]\tvalid_0's rmse: 1.99662\n",
      "[300]\tvalid_0's rmse: 1.95708\n",
      "[400]\tvalid_0's rmse: 1.93073\n",
      "[500]\tvalid_0's rmse: 1.90684\n",
      "[600]\tvalid_0's rmse: 1.88948\n",
      "[700]\tvalid_0's rmse: 1.86964\n",
      "[800]\tvalid_0's rmse: 1.85379\n",
      "[900]\tvalid_0's rmse: 1.84074\n",
      "[1000]\tvalid_0's rmse: 1.82464\n",
      "[1100]\tvalid_0's rmse: 1.80797\n",
      "[1200]\tvalid_0's rmse: 1.79867\n",
      "[1300]\tvalid_0's rmse: 1.78879\n",
      "[1400]\tvalid_0's rmse: 1.77614\n",
      "[1500]\tvalid_0's rmse: 1.76207\n",
      "[1600]\tvalid_0's rmse: 1.75245\n",
      "[1700]\tvalid_0's rmse: 1.74071\n",
      "[1800]\tvalid_0's rmse: 1.7313\n",
      "[1900]\tvalid_0's rmse: 1.72059\n",
      "[2000]\tvalid_0's rmse: 1.71492\n",
      "[2100]\tvalid_0's rmse: 1.70626\n",
      "[2200]\tvalid_0's rmse: 1.6955\n",
      "TX_2开始啦---------------------------------------\n",
      "[100]\tvalid_0's rmse: 2.78135\n",
      "[200]\tvalid_0's rmse: 2.50994\n",
      "[300]\tvalid_0's rmse: 2.30395\n",
      "[400]\tvalid_0's rmse: 2.1606\n",
      "[500]\tvalid_0's rmse: 2.10139\n",
      "[600]\tvalid_0's rmse: 2.05176\n",
      "[700]\tvalid_0's rmse: 2.02297\n",
      "[800]\tvalid_0's rmse: 1.99782\n",
      "[900]\tvalid_0's rmse: 1.98494\n",
      "[1000]\tvalid_0's rmse: 1.9699\n",
      "[1100]\tvalid_0's rmse: 1.95857\n",
      "[1200]\tvalid_0's rmse: 1.94935\n",
      "[1300]\tvalid_0's rmse: 1.93894\n",
      "[1400]\tvalid_0's rmse: 1.93118\n",
      "[1500]\tvalid_0's rmse: 1.91836\n",
      "[1600]\tvalid_0's rmse: 1.90423\n",
      "[1700]\tvalid_0's rmse: 1.90454\n",
      "[1800]\tvalid_0's rmse: 1.8878\n",
      "[1900]\tvalid_0's rmse: 1.87766\n",
      "[2000]\tvalid_0's rmse: 1.86703\n",
      "[2100]\tvalid_0's rmse: 1.85987\n",
      "[2200]\tvalid_0's rmse: 1.84991\n",
      "TX_3开始啦---------------------------------------\n",
      "[100]\tvalid_0's rmse: 2.12707\n",
      "[200]\tvalid_0's rmse: 2.03808\n",
      "[300]\tvalid_0's rmse: 1.98624\n",
      "[400]\tvalid_0's rmse: 1.9505\n",
      "[500]\tvalid_0's rmse: 1.92148\n",
      "[600]\tvalid_0's rmse: 1.90426\n",
      "[700]\tvalid_0's rmse: 1.88601\n",
      "[800]\tvalid_0's rmse: 1.86861\n",
      "[900]\tvalid_0's rmse: 1.85465\n",
      "[1000]\tvalid_0's rmse: 1.83602\n",
      "[1100]\tvalid_0's rmse: 1.82783\n",
      "[1200]\tvalid_0's rmse: 1.81539\n",
      "[1300]\tvalid_0's rmse: 1.80573\n",
      "[1400]\tvalid_0's rmse: 1.80059\n",
      "[1500]\tvalid_0's rmse: 1.78634\n",
      "[1600]\tvalid_0's rmse: 1.77113\n",
      "[1700]\tvalid_0's rmse: 1.75857\n",
      "[1800]\tvalid_0's rmse: 1.7492\n",
      "[1900]\tvalid_0's rmse: 1.74203\n",
      "[2000]\tvalid_0's rmse: 1.7322\n",
      "[2100]\tvalid_0's rmse: 1.72334\n",
      "[2200]\tvalid_0's rmse: 1.71461\n",
      "WI_1开始啦---------------------------------------\n",
      "[100]\tvalid_0's rmse: 1.6331\n",
      "[200]\tvalid_0's rmse: 1.59371\n",
      "[300]\tvalid_0's rmse: 1.56823\n",
      "[400]\tvalid_0's rmse: 1.55191\n",
      "[500]\tvalid_0's rmse: 1.53643\n",
      "[600]\tvalid_0's rmse: 1.52662\n",
      "[700]\tvalid_0's rmse: 1.515\n",
      "[800]\tvalid_0's rmse: 1.50744\n",
      "[900]\tvalid_0's rmse: 1.49996\n",
      "[1000]\tvalid_0's rmse: 1.49365\n",
      "[1100]\tvalid_0's rmse: 1.48675\n",
      "[1200]\tvalid_0's rmse: 1.47975\n",
      "[1300]\tvalid_0's rmse: 1.47428\n",
      "[1400]\tvalid_0's rmse: 1.46739\n",
      "[1500]\tvalid_0's rmse: 1.46198\n",
      "[1600]\tvalid_0's rmse: 1.45455\n",
      "[1700]\tvalid_0's rmse: 1.4498\n",
      "[1800]\tvalid_0's rmse: 1.44413\n",
      "[1900]\tvalid_0's rmse: 1.43949\n",
      "[2000]\tvalid_0's rmse: 1.43536\n",
      "[2100]\tvalid_0's rmse: 1.42988\n",
      "[2200]\tvalid_0's rmse: 1.42499\n",
      "WI_2开始啦---------------------------------------\n",
      "[100]\tvalid_0's rmse: 2.51457\n",
      "[200]\tvalid_0's rmse: 2.40087\n",
      "[300]\tvalid_0's rmse: 2.32255\n",
      "[400]\tvalid_0's rmse: 2.26591\n",
      "[500]\tvalid_0's rmse: 2.21133\n",
      "[600]\tvalid_0's rmse: 2.17698\n",
      "[700]\tvalid_0's rmse: 2.14766\n",
      "[800]\tvalid_0's rmse: 2.11987\n",
      "[900]\tvalid_0's rmse: 2.09258\n",
      "[1000]\tvalid_0's rmse: 2.06577\n",
      "[1100]\tvalid_0's rmse: 2.04494\n",
      "[1200]\tvalid_0's rmse: 2.03163\n",
      "[1300]\tvalid_0's rmse: 2.01624\n",
      "[1400]\tvalid_0's rmse: 2.00395\n",
      "[1500]\tvalid_0's rmse: 1.98462\n",
      "[1600]\tvalid_0's rmse: 1.97123\n",
      "[1700]\tvalid_0's rmse: 1.95777\n",
      "[1800]\tvalid_0's rmse: 1.94408\n",
      "[1900]\tvalid_0's rmse: 1.93263\n",
      "[2000]\tvalid_0's rmse: 1.92032\n",
      "[2100]\tvalid_0's rmse: 1.90842\n",
      "[2200]\tvalid_0's rmse: 1.89642\n",
      "WI_3开始啦---------------------------------------\n",
      "[100]\tvalid_0's rmse: 2.17024\n",
      "[200]\tvalid_0's rmse: 2.08848\n",
      "[300]\tvalid_0's rmse: 2.03098\n",
      "[400]\tvalid_0's rmse: 1.99026\n",
      "[500]\tvalid_0's rmse: 1.96534\n",
      "[600]\tvalid_0's rmse: 1.94334\n",
      "[700]\tvalid_0's rmse: 1.92021\n",
      "[800]\tvalid_0's rmse: 1.90059\n",
      "[900]\tvalid_0's rmse: 1.88508\n",
      "[1000]\tvalid_0's rmse: 1.86004\n",
      "[1100]\tvalid_0's rmse: 1.84395\n",
      "[1200]\tvalid_0's rmse: 1.83167\n",
      "[1300]\tvalid_0's rmse: 1.81685\n",
      "[1400]\tvalid_0's rmse: 1.80549\n",
      "[1500]\tvalid_0's rmse: 1.79407\n",
      "[1600]\tvalid_0's rmse: 1.78117\n",
      "[1700]\tvalid_0's rmse: 1.77013\n",
      "[1800]\tvalid_0's rmse: 1.76218\n",
      "[1900]\tvalid_0's rmse: 1.75438\n",
      "[2000]\tvalid_0's rmse: 1.74589\n",
      "[2100]\tvalid_0's rmse: 1.73707\n",
      "[2200]\tvalid_0's rmse: 1.72984\n"
     ]
    }
   ],
   "source": [
    "for name,day in zip(store,starDay):\n",
    "    \n",
    "    sale_data = create_train_data(train_start=day,end=1913,is_train=True,name=name)\n",
    "    sale_data = create_feature(sale_data)\n",
    "\n",
    "    # 清洗数据，选择需要训练的数据\n",
    "    sale_data.dropna(inplace=True)\n",
    "    \n",
    "    cat_feats = ['item_id', 'dept_id', 'cat_id'] + [\"event_name_1\",'event_type_1'] + future\n",
    "    useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\",'store_id','state_id']# + future\n",
    "    train_cols = sale_data.columns[~sale_data.columns.isin(useless_cols)]\n",
    "    X_train = sale_data[train_cols]\n",
    "    y_train = sale_data[\"sales\"]\n",
    "    train_data = lgb.Dataset(X_train, label = y_train, categorical_feature=cat_feats, free_raw_data=False)\n",
    "    valid_inds = np.random.choice(len(X_train), 100000)\n",
    "    valid_data = lgb.Dataset(X_train.iloc[valid_inds], label = y_train.iloc[valid_inds],categorical_feature=cat_feats, free_raw_data=False)\n",
    "    print(\"{}开始啦---------------------------------------\".format(name))\n",
    "    m_lgb = train_model(train_data,valid_data)\n",
    "    #m_lgb.save_model(f'{name}.txt')\n",
    "    predict_ensemble_NoWeight(train_cols,m_lgb,name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "train_colums = ['item_id', 'dept_id', 'cat_id', 'wday', 'month', 'year', 'event_name_1',\n",
    "       'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX',\n",
    "       'snap_WI', 'sell_price', 'lag_7', 'lag_28', 'rmean_7_7', 'rmean_28_7',\n",
    "       'rmean_7_28', 'rmean_28_28', 'week', 'quarter', 'mday']\n",
    "for name in store:\n",
    "    gbm = lgb.Booster(model_file=name+'.txt') #载入模型\n",
    "    pd.DataFrame({\n",
    "        'column': X_train.columns,\n",
    "        'importance': m_lgb.feature_importance(),\n",
    "    }).sort_values(by='importance')\n",
    "    predict_ensemble(train_cols,gbm,name)#预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#观察模型权重\n",
    "im_fe = []\n",
    "for name in store:\n",
    "    gbm = lgb.Booster(model_file=name+'.txt') #载入模型\n",
    "    im_fe.append(pd.DataFrame({\n",
    "        'column': X_train.columns,\n",
    "        'importance': gbm.feature_importance(),\n",
    "    }).sort_values(by='importance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "        'column': X_train.columns,\n",
    "        'importance': m_lgb.feature_importance(),\n",
    "    }).sort_values(by='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调参\n",
    "from hyperopt import fmin, tpe, hp, partial\n",
    "# 自定义hyperopt的参数空间\n",
    "space = {\"max_depth\": hp.randint(\"max_depth\", 10),\n",
    "         \"num_trees\": hp.randint(\"num_trees\", 300),\n",
    "         'learning_rate': hp.uniform('learning_rate', 1e-3, 5e-1),\n",
    "         \"bagging_fraction\": hp.randint(\"bagging_fraction\", 5),\n",
    "         \"num_leaves\": hp.randint(\"num_leaves\", 50),\n",
    "         'sub_row': hp.uniform('sub_row',0, 1),\n",
    "         'sub_feature': hp.uniform('sub_feature',0, 1),\n",
    "         'lambda_l2': hp.uniform('lambda_l2',0, 1),\n",
    "         'num_leaves': hp.randint('num_leaves', 120),\n",
    "         'min_data_in_leaf': hp.randint('min_data_in_leaf', 100),\n",
    "         'tweedie_variance_power': hp.uniform('tweedie_variance_power',0,1)\n",
    "                 \n",
    "         }\n",
    "\n",
    "def argsDict_tranform(argsDict, isPrint=False):\n",
    "    argsDict[\"max_depth\"] = argsDict[\"max_depth\"] + 5\n",
    "    argsDict['num_trees'] = argsDict['num_trees'] + 100\n",
    "    argsDict[\"learning_rate\"] = argsDict[\"learning_rate\"] * 0.02 + 0.05\n",
    "    argsDict[\"bagging_fraction\"] = argsDict[\"bagging_fraction\"] * 0.1 + 0.5\n",
    "    argsDict[\"num_leaves\"] = argsDict[\"num_leaves\"] * 3 + 10\n",
    "    argsDict['tweedie_variance_power'] = argsDict['tweedie_variance_power'] + 1\n",
    "    argsDict['min_data_in_leaf'] = argsDict['min_data_in_leaf'] + 50\n",
    "    if isPrint:\n",
    "        print(argsDict)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return argsDict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def lightgbm_factory(argsDict):\n",
    "    argsDict = argsDict_tranform(argsDict)\n",
    "\n",
    "    params = {'nthread': -1,  # 进程数\n",
    "              'max_depth': argsDict['max_depth'],  # 最大深度\n",
    "              'num_trees': argsDict['num_trees'],  # 树的数量\n",
    "              #'eta': argsDict['learning_rate'],  # 学习率\n",
    "              'bagging_fraction': argsDict['bagging_fraction'],  # 采样数\n",
    "              'num_leaves': argsDict['num_leaves'],  # 终点节点最小样本占比的和\n",
    "              'objective': 'tweedie',\n",
    "              #'feature_fraction': 0.7,  # 样本列采样\n",
    "              #'lambda_l1': 0,  # L1 正则化\n",
    "              'lambda_l2': argsDict['lambda_l2'] ,  # L2 正则化\n",
    "              'bagging_seed': 100,  # 随机种子,light中默认为100\n",
    "              'force_row_wise': True,\n",
    "              'learning_rate': argsDict['learning_rate'],\n",
    "              'sub_feature': argsDict['sub_feature'],\n",
    "              'sub_row': argsDict['sub_row'],\n",
    "              'tweedie_variance_power': argsDict['tweedie_variance_power'],\n",
    "              'num_iterations': 1500,\n",
    "              \n",
    "              }\n",
    "    params['metric'] = ['rmse']\n",
    "\n",
    "    model_lgb = lgb.train(params, train_data, valid_sets=[valid_data],verbose_eval=100)\n",
    "\n",
    "    return get_tranformer_score(model_lgb)\n",
    "\n",
    "def get_tranformer_score(tranformer):\n",
    "\n",
    "    model = tranformer\n",
    "    prediction = model.predict(test_data, num_iteration=model.best_iteration)\n",
    "\n",
    "    return np.sqrt(mean_squared_error(y_predict, prediction))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n",
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n",
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1382: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.04736                         \n",
      "[200]\tvalid_0's rmse: 2.02012                         \n",
      "[100]\tvalid_0's rmse: 2.0365                                                    \n",
      "[100]\tvalid_0's rmse: 2.28566                                                   \n",
      "[200]\tvalid_0's rmse: 2.06662                                                   \n",
      "[300]\tvalid_0's rmse: 2.03152                                                   \n",
      "[100]\tvalid_0's rmse: 1.87176                                                   \n",
      "[100]\tvalid_0's rmse: 1.8336                                                    \n",
      "[100]\tvalid_0's rmse: 1.89371                                                   \n",
      "[200]\tvalid_0's rmse: 1.84347                                                   \n",
      "[100]\tvalid_0's rmse: 2.14041                                                   \n",
      "[100]\tvalid_0's rmse: 2.04612                                                   \n",
      "[200]\tvalid_0's rmse: 2.01594                                                   \n",
      "[300]\tvalid_0's rmse: 1.99384                                                   \n",
      "[100]\tvalid_0's rmse: 2.05068                                                    \n",
      "[100]\tvalid_0's rmse: 1.98322                                                    \n",
      "[100]\tvalid_0's rmse: 2.00734                                                     \n",
      "[100]\tvalid_0's rmse: 1.99817                                                     \n",
      "[200]\tvalid_0's rmse: 1.95429                                                    \n",
      "[100]\tvalid_0's rmse: 1.95989                                                    \n",
      "[100]\tvalid_0's rmse: 2.14541                                                    \n",
      "[100]\tvalid_0's rmse: 1.95983                                                    \n",
      "[200]\tvalid_0's rmse: 1.91707                                                    \n",
      "[300]\tvalid_0's rmse: 1.88167                                                    \n",
      "[100]\tvalid_0's rmse: 2.01524                                                    \n",
      "[200]\tvalid_0's rmse: 1.98415                                                    \n",
      "[300]\tvalid_0's rmse: 1.96607                                                    \n",
      "[100]\tvalid_0's rmse: 1.84133                                                     \n",
      "[200]\tvalid_0's rmse: 1.77522                                                     \n",
      "[300]\tvalid_0's rmse: 1.7208                                                      \n",
      "[100]\tvalid_0's rmse: 1.79091                                                     \n",
      "[200]\tvalid_0's rmse: 1.72316                                                     \n",
      "[300]\tvalid_0's rmse: 1.67536                                                     \n",
      "[100]\tvalid_0's rmse: 1.96545                                                     \n",
      "[200]\tvalid_0's rmse: 1.90347                                                     \n",
      "[300]\tvalid_0's rmse: 1.8709                                                      \n",
      "[100]\tvalid_0's rmse: 2.07281                                                     \n",
      "100%|██████████| 20/20 [31:52<00:00, 95.61s/trial, best loss: 1.5961147354660095] \n"
     ]
    }
   ],
   "source": [
    "# 开始使用hyperopt进行自动调参\n",
    "algo = partial(tpe.suggest, n_startup_jobs=1)\n",
    "best = fmin(lightgbm_factory, space, algo=algo, max_evals=20, pass_expr_memo_ctrl=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1382: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 1.79091\n",
      "[200]\tvalid_0's rmse: 1.72316\n",
      "[300]\tvalid_0's rmse: 1.67536\n",
      "best : {'bagging_fraction': 0.5, 'lambda_l2': 0.05011344402963704, 'learning_rate': 0.058374900891665485, 'max_depth': 12, 'min_data_in_leaf': 69, 'num_leaves': 295, 'num_trees': 388, 'sub_feature': 0.9989461548041529, 'sub_row': 0.06543578939994449, 'tweedie_variance_power': 1.1107920722132256}\n",
      "best param after transform :\n",
      "{'bagging_fraction': 0.55, 'lambda_l2': 0.05011344402963704, 'learning_rate': 0.05116749801783331, 'max_depth': 17, 'min_data_in_leaf': 119, 'num_leaves': 895, 'num_trees': 488, 'sub_feature': 0.9989461548041529, 'sub_row': 0.06543578939994449, 'tweedie_variance_power': 2.1107920722132256}\n",
      "rmse of the best lightgbm: 1.5961147354660095\n"
     ]
    }
   ],
   "source": [
    "RMSE = lightgbm_factory(best)\n",
    "print('best :', best)\n",
    "print('best param after transform :')\n",
    "argsDict_tranform(best,isPrint=True)\n",
    "print('rmse of the best lightgbm:', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1382: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1117: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/Users/xuelei/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:929: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.39327\n",
      "[200]\tvalid_0's rmse: 2.27406\n",
      "[300]\tvalid_0's rmse: 2.22258\n",
      "[400]\tvalid_0's rmse: 2.18071\n",
      "[500]\tvalid_0's rmse: 2.15637\n",
      "[600]\tvalid_0's rmse: 2.13176\n",
      "[700]\tvalid_0's rmse: 2.11441\n",
      "[800]\tvalid_0's rmse: 2.09014\n",
      "[900]\tvalid_0's rmse: 2.06851\n",
      "[1000]\tvalid_0's rmse: 2.04812\n",
      "[1100]\tvalid_0's rmse: 2.02672\n"
     ]
    }
   ],
   "source": [
    "m_lgb = train_model(train_data,valid_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7372964460575426\n"
     ]
    }
   ],
   "source": [
    "y_true = sale.loc[:,'d_1886':'d_1913']\n",
    "pre = pd.read_csv('submissionV3.csv').loc[:30489,'F1':]\n",
    "print(wrmsse(pre,y_true,False,S,W,SW)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# \"\"\"\n",
    "# Created on Wed Apr 29 13:29:28 2020\n",
    "\n",
    "# @author: Lebesgue\n",
    "# \"\"\"\n",
    "# 线下验证\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import csr_matrix\n",
    "import gc\n",
    "import os \n",
    "# #os.chdir('G:/kaggle/M5/juyterD')\n",
    "\n",
    "# # 1914 1886 \n",
    "# # 1913 1885\n",
    "\n",
    "# # 转换数据类型，减少内存占用空间\n",
    "# def reduce_mem_usage(df, verbose=True):\n",
    "# # =============================================================================\n",
    "# #     df = calendar\n",
    "# # =============================================================================\n",
    "#     numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "#     start_mem = df.memory_usage().sum() / 1024**2    \n",
    "#     for col in df.columns:\n",
    "#         col_type = df[col].dtypes\n",
    "#         if col_type in numerics: \n",
    "#             c_min = df[col].min()\n",
    "#             c_max = df[col].max()\n",
    "#             if str(col_type)[:3] == 'int':\n",
    "#                 if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "#                     df[col] = df[col].astype(np.int8)\n",
    "#                 elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "#                     df[col] = df[col].astype(np.int16)\n",
    "#                 elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "#                     df[col] = df[col].astype(np.int32)\n",
    "#                 elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "#                     df[col] = df[col].astype(np.int64)  \n",
    "#             else:\n",
    "#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "#                     df[col] = df[col].astype(np.float16)\n",
    "#                 elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "#                     df[col] = df[col].astype(np.float32)\n",
    "#                 else:\n",
    "#                     df[col] = df[col].astype(np.float64)    \n",
    "#     end_mem = df.memory_usage().sum() / 1024**2\n",
    "#     if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "#     return df\n",
    "\n",
    "\n",
    "# # 加载数据\n",
    "# data_pass = './m5-forecasting-accuracy/'\n",
    "\n",
    "# # sale数据\n",
    "# sales = pd.read_csv('sales_train_validation.csv') \n",
    "\n",
    "# # 日期数据\n",
    "# calendar = pd.read_csv('calendar.csv')\n",
    "# calendar = reduce_mem_usage(calendar)\n",
    "\n",
    "# # 价格数据\n",
    "# sell_prices = pd.read_csv('sell_prices.csv')\n",
    "# sell_prices = reduce_mem_usage(sell_prices)\n",
    "\n",
    "# # 计算价格\n",
    "# # 按照定义，只需要计算最近的 28 天售卖量（售卖数*价格），通过这个可以得到 weight\n",
    "# # 可以不是 1886\n",
    "# cols = [\"d_{}\".format(i) for i in range(1886-28, 1886)]\n",
    "# data = sales[[\"id\", 'store_id', 'item_id'] + cols]\n",
    "\n",
    "# # 从横表改为纵表\n",
    "# data = data.melt(id_vars=[\"id\", 'store_id', 'item_id'], \n",
    "#                  var_name=\"d\", value_name=\"sale\")\n",
    "\n",
    "# # 和日期数据做关联\n",
    "# data = pd.merge(data, calendar, how = 'left', \n",
    "#                 left_on = ['d'], right_on = ['d'])\n",
    "\n",
    "# data = data[[\"id\", 'store_id', 'item_id', \"sale\", \"d\", \"wm_yr_wk\"]]\n",
    "\n",
    "# # 和价格数据关联\n",
    "# data = data.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "# data.drop(columns = ['wm_yr_wk'], inplace=True)\n",
    "\n",
    "# # 计算售卖量总价（售卖数量*商品单价）\n",
    "# data['sale_usd'] = data['sale'] * data['sell_price']\n",
    "\n",
    "# # 得到聚合矩阵\n",
    "# # 30490 -> 42840\n",
    "# # 需要聚合的维度明细计算出来 \n",
    "# # 根据图片【聚合】对应下面就是\n",
    "# # 2 3 4 5 6 7 8 9 10 11 12  \n",
    "# dummies_list = [sales.state_id, sales.store_id, \n",
    "#                 sales.cat_id, sales.dept_id, \n",
    "#                 sales.state_id + sales.cat_id, sales.state_id + sales.dept_id,\n",
    "#                 sales.store_id + sales.cat_id, sales.store_id + sales.dept_id, \n",
    "#                 sales.item_id, sales.state_id + sales.item_id, sales.id]\n",
    "\n",
    "# # =============================================================================\n",
    "# # dummies_list = [sales.state_id + sales.item_id]\n",
    "# # =============================================================================\n",
    "\n",
    "\n",
    "# # 全部聚合为一个， 最高 level \n",
    "# # 即 1 \n",
    "# dummies_df_list =[pd.DataFrame(np.ones(sales.shape[0]).astype(np.int8), \n",
    "#                                index=sales.index, columns=['all']).T]\n",
    "\n",
    "# # 挨个计算其他 level 等级聚合\n",
    "# for i, cats in enumerate(dummies_list):\n",
    "#     #print(i)\n",
    "#     dummies_df_list +=[pd.get_dummies(cats, drop_first=False, dtype=np.int8).T]\n",
    "    \n",
    "# # 得到聚合矩阵\n",
    "# roll_mat_df = pd.concat(dummies_df_list, keys=list(range(12)), \n",
    "#                         names=['level','id'])#.astype(np.int8, copy=False)\n",
    "\n",
    "# # =============================================================================\n",
    "# #                                        0      1      2      ...  30487  30488  30489\n",
    "# # level id                                                    ...                     \n",
    "# # 0     all                                  1      1      1  ...      1      1      1\n",
    "# # 1     CA                                   1      1      1  ...      0      0      0\n",
    "# #       TX                                   0      0      0  ...      0      0      0\n",
    "# #       WI                                   0      0      0  ...      1      1      1\n",
    "# # 2     CA_1                                 1      1      1  ...      0      0      0\n",
    "# #                                      ...    ...    ...  ...    ...    ...    ...\n",
    "# # 11    HOUSEHOLD_2_516_TX_2_validation      0      0      0  ...      0      0      0\n",
    "# #       HOUSEHOLD_2_516_TX_3_validation      0      0      0  ...      0      0      0\n",
    "# #       HOUSEHOLD_2_516_WI_1_validation      0      0      0  ...      0      0      0\n",
    "# #       HOUSEHOLD_2_516_WI_2_validation      0      0      0  ...      0      0      0\n",
    "# #       HOUSEHOLD_2_516_WI_3_validation      0      0      0  ...      0      0      0\n",
    "# # =============================================================================\n",
    "      \n",
    "# # 保存聚合矩阵 \n",
    "# # 将矩阵的索引保存  \n",
    "# roll_index = roll_mat_df.index \n",
    "\n",
    "# # =============================================================================\n",
    "# # MultiIndex([( 0,                             'all'),\n",
    "# #             ( 1,                              'CA'),\n",
    "# #             ( 1,                              'TX'),\n",
    "# #             ( 1,                              'WI'),\n",
    "# #             ( 2,                            'CA_1'),\n",
    "# #             ( 2,                            'CA_2'),\n",
    "# #             ( 2,                            'CA_3'),\n",
    "# #             ( 2,                            'CA_4'),\n",
    "# #             ( 2,                            'TX_1'),\n",
    "# #             ( 2,                            'TX_2'),\n",
    "# #             ...\n",
    "# #             (11, 'HOUSEHOLD_2_516_CA_1_validation'),\n",
    "# #             (11, 'HOUSEHOLD_2_516_CA_2_validation'),\n",
    "# #             (11, 'HOUSEHOLD_2_516_CA_3_validation'),\n",
    "# #             (11, 'HOUSEHOLD_2_516_CA_4_validation'),\n",
    "# #             (11, 'HOUSEHOLD_2_516_TX_1_validation'),\n",
    "# #             (11, 'HOUSEHOLD_2_516_TX_2_validation'),\n",
    "# #             (11, 'HOUSEHOLD_2_516_TX_3_validation'),\n",
    "# #             (11, 'HOUSEHOLD_2_516_WI_1_validation'),\n",
    "# #             (11, 'HOUSEHOLD_2_516_WI_2_validation'),\n",
    "# #             (11, 'HOUSEHOLD_2_516_WI_3_validation')],\n",
    "# #            names=['level', 'id'], length=42840)\n",
    "# # =============================================================================\n",
    "\n",
    "# # 将矩阵的值也保存 \n",
    "# roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "# roll_mat_df.to_pickle('roll_mat_df.pkl')\n",
    "\n",
    "# # 销毁对象 \n",
    "# # 即销毁连接前的各个聚合组合的数列 与 连接后的矩阵 \n",
    "# del dummies_df_list, roll_mat_df\n",
    "\n",
    "# # 释放内存\n",
    "# gc.collect()\n",
    "\n",
    "\n",
    "# # 按照定义，计算每条时间序列 RMSSE 的权重:\n",
    "# def get_s(drop_days=0):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     drop_days: int, equals 0 by default, so S is calculated on all data.\n",
    "#                If equals 28, last 28 days won't be used in calculating S.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # 要计算的时间序列长度 \n",
    "#     # 如果drop_days为0 则有d_1 ~ d_1885 \n",
    "#     d_name = ['d_' + str(i+1) for i in range(1885-drop_days)]\n",
    "#     # 得到聚合结果 \n",
    "#     # 矩阵乘法 (42840, 30490) * (30490, 1885) = (42840, 1885) \n",
    "#     # roll_mat_csr : 行为每个聚合层次 列为30490条销售索引 值代表取某列时属于某行的就标记1 否则为0 \n",
    "#     # 列即为唯一商品id的索引 所以可以这么理解 如果aij=1 则意味着索引为j所对应的商品在i聚合层次里面有销售记录 \n",
    "#     # sales[d_name] :  行为30489条销售索引 列为d_name那么多天的天字段 值为销售量 \n",
    "#     # 结果即为每个聚合层次（行） d_name那么多天（行）的每天 的销售量 如果i为行 j为列 那么aij就是\n",
    "#     # 第i个聚合层次下 j这天的销售量  \n",
    "#     # 也可以这么写 roll_mat_csr @ sales[d_name].values\n",
    "#     sales_train_val = roll_mat_csr * sales[d_name].values\n",
    "\n",
    "#     # 按照定义，前面连续为 0 的不参与计算 \n",
    "#     # 即找出每个聚类层次 前面连续取值为0（销售量为0的天）不参与计算 返回的是第一个不为0 的列索引j（第j-1天） \n",
    "#     start_no = np.argmax(sales_train_val>0, axis=1)\n",
    "    \n",
    "#     # 这些连续为 0 的设置为 nan \n",
    "#     # flag 的形状与 sales_train_val 的形状一致 \n",
    "#     # np.diag(1/(start_no+1)) 对角矩阵 (42840, 42840) 加1的原因 一是为了分母非0 二是为了等下矩阵相乘 \n",
    "#     # 能起到用是否小于1来判断该聚类层次的第几天开始是第一个非0的 \n",
    "#     # 例如 第一行的聚类层次 在列索引j等于3的时候（即第4天）才开始不为0 则对角矩阵的第一个元素是 1/4 \n",
    "#     # 乘过去后面一部分的第一行时 因其值为1 2 3 4 5...1885 那么除以4的话有 1/4 2/4 3/4 4/4 5/4 \n",
    "#     # 可见只要判断是否小于1 就能把第一个非0值对应的天找出来 这里就是第4天了 因为4/4不小于1 \n",
    "#     # 后面一部分的为 (42840, 1885) 生成的过程 里面是A:(1885, ) B:(42840, 1) A按照列方向复制了42840行 \n",
    "# # =============================================================================\n",
    "# #     flag = np.dot(np.diag(1/(start_no+1)), np.tile(np.arange(1,1886-drop_days),(roll_mat_csr.shape[0],1)))<1 \n",
    "# # =============================================================================\n",
    "#     # 上述对角阵内存开销较大 可以利用数组的广播功能 将其写成如下等价的式子 \n",
    "# # =============================================================================\n",
    "# #     flag = (1/(start_no+1)).reshape(len(start_no), -1) * np.tile(np.arange(1,1886-drop_days),(roll_mat_csr.shape[0],1)) < 1 \n",
    "# # =============================================================================\n",
    "#     # 事实上还可以把右边的部分同样利用数组的广播功能 免去tile 即等价于下面的式子 \n",
    "#     flag = (1/(start_no+1)).reshape(len(start_no), -1) * np.arange(1,1886-drop_days) < 1\n",
    "#     # 上式也可以写成规整一点的形式 \n",
    "#     # (1/(start_no+1)).reshape(len(start_no), -1) * np.arange(1,1886-drop_days).reshape(-1, len(np.arange(1,1886-drop_days)))\n",
    "#     # 返回的flag是如果上述矩阵乘积的值小于1（即连续为0的那些天） 则返回True 否则为False  \n",
    "#     # np.where 作用是根据flag的布尔值 如果为True 则设置为nan 否则取sales_train_val原值 \n",
    "#     sales_train_val = np.where(flag, np.nan, sales_train_val)\n",
    "\n",
    "#     # 根据公式计算每条时间序列 rmsse的权重\n",
    "#     # nansum忽略nan 对非nan进行相加 \n",
    "#     # 就是公式分母那一部分 但不包含h \n",
    "#     weight1 = np.nansum(np.diff(sales_train_val,axis=1)**2,axis=1)/(1885-start_no-1)\n",
    "    \n",
    "#     return weight1\n",
    "\n",
    "# # 每个聚合层次的权重 \n",
    "# S = get_s(drop_days=0)\n",
    "\n",
    "# # 根据定义计算 WRMSSE 的权重，这里指 w \n",
    "# def get_w(sale_usd):\n",
    "# # =============================================================================\n",
    "# #     sale_usd = data[['id','sale_usd']]\n",
    "# # =============================================================================\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     # 得到最细维度的每条时间序列的权重 \n",
    "#     # 30490个唯一商品id 形状为(30490,) 聚合求出对应的销售量 \n",
    "#     total_sales_usd = sale_usd.groupby(\n",
    "#         ['id'], sort=False)['sale_usd'].apply(np.sum).values\n",
    "    \n",
    "#     # 通过聚合矩阵得到不同聚合下的权重\n",
    "#     # (42840,) = (42840, 30490) * (30490,) \n",
    "#     weight2 = roll_mat_csr * total_sales_usd\n",
    "#     # 因为聚合层次一共有12 所以需要乘以12  这里的分母np.sum(weight2)是进行了12次的加和,乘以12是为了变成一次的加和\n",
    "#     return 12*(weight2/np.sum(weight2))\n",
    "\n",
    "\n",
    "# W = get_w(data[['id','sale_usd']])\n",
    "\n",
    "# SW = W/np.sqrt(S)\n",
    "\n",
    "# sw_df = pd.DataFrame(np.stack((S, W, SW), axis=-1),index = roll_index,columns=['s','w','sw'])\n",
    "# sw_df.to_pickle('sw_df.pkl')\n",
    "\n",
    "\n",
    "# 评分函数\n",
    "# 得到聚合的结果\n",
    "def rollup(v):\n",
    "    '''\n",
    "    '''\n",
    "    return (v.T*roll_mat_csr.T).T\n",
    "\n",
    "\n",
    "# 计算 WRMSSE 评估指标\n",
    "def wrmsse(preds, y_true, score_only=False,s = S, w = W, sw=SW):\n",
    "    '''\n",
    "    preds - Predictions: pd.DataFrame of size (30490 rows, N day columns)\n",
    "    y_true - True values: pd.DataFrame of size (30490 rows, N day columns)\n",
    "    sequence_length - np.array of size (42840,)\n",
    "    sales_weight - sales weights based on last 28 days: np.array (42840,)\n",
    "    '''\n",
    "    \n",
    "    if score_only:\n",
    "        return np.sum(\n",
    "                np.sqrt(\n",
    "                    np.mean(\n",
    "                        np.square(rollup(preds.values-y_true.values))\n",
    "                            ,axis=1)) * sw *(1/12))\n",
    "    else: \n",
    "        score_matrix = (np.square(rollup(preds.values-y_true.values)) * np.square(w)[:, None]) / s[:, None]\n",
    "        score = np.sum(np.sqrt(np.mean(score_matrix,axis=1)))*(1/12)\n",
    "        return score, score_matrix\n",
    "\n",
    "\n",
    "# 加载前面预先计算好的各个权重\n",
    "file_pass = './'\n",
    "sw_df = pd.read_pickle(file_pass+'sw_df.pkl')\n",
    "S = sw_df.s.values\n",
    "W = sw_df.w.values\n",
    "SW = sw_df.sw.values\n",
    "\n",
    "roll_mat_df = pd.read_pickle(file_pass+'roll_mat_df.pkl')\n",
    "roll_index = roll_mat_df.index\n",
    "roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "\n",
    "# =============================================================================\n",
    "# print(sw_df.loc[(11,slice(None))].sw)\n",
    "# \n",
    "# print(1)\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7239263233868902\n"
     ]
    }
   ],
   "source": [
    "y_true = sale_data.loc[:,'d_1886':'d_1913']\n",
    "pre = pd.read_csv('submissionV3.csv').loc[:30489,'F1':]\n",
    "print(wrmsse(pre,y_true,False,S,W,SW)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1',\n",
    "       'WI_2', 'WI_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA1 = pd.read_csv('CA_1_sub.csv')\n",
    "CA2 = pd.read_csv('CA_2_sub.csv')\n",
    "CA3 = pd.read_csv('CA_3_sub.csv')\n",
    "CA4 = pd.read_csv('CA_4_sub.csv')\n",
    "TX1 = pd.read_csv('TX_1_sub.csv')\n",
    "TX2 = pd.read_csv('TX_2_sub.csv')\n",
    "TX3 = pd.read_csv('TX_3_sub.csv')\n",
    "WI1 = pd.read_csv('WI_1_sub.csv')\n",
    "WI2 = pd.read_csv('WI_2_sub.csv')\n",
    "WI3 = pd.read_csv('WI_3_sub.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fram = [CA1,CA2,CA3,CA4,TX1,TX2,TX3,WI1,WI2,WI3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(fram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60980, 29)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>0.750139</td>\n",
       "      <td>0.772505</td>\n",
       "      <td>0.771933</td>\n",
       "      <td>0.783363</td>\n",
       "      <td>0.942362</td>\n",
       "      <td>0.919770</td>\n",
       "      <td>1.248111</td>\n",
       "      <td>0.899572</td>\n",
       "      <td>0.786103</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031215</td>\n",
       "      <td>1.129099</td>\n",
       "      <td>1.070506</td>\n",
       "      <td>0.760960</td>\n",
       "      <td>0.719134</td>\n",
       "      <td>0.720440</td>\n",
       "      <td>0.709261</td>\n",
       "      <td>0.935049</td>\n",
       "      <td>1.028566</td>\n",
       "      <td>1.007027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_002_CA_1_validation</td>\n",
       "      <td>0.479268</td>\n",
       "      <td>0.430599</td>\n",
       "      <td>0.407865</td>\n",
       "      <td>0.411677</td>\n",
       "      <td>0.419198</td>\n",
       "      <td>0.259251</td>\n",
       "      <td>0.384414</td>\n",
       "      <td>0.392110</td>\n",
       "      <td>0.494740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463434</td>\n",
       "      <td>0.627420</td>\n",
       "      <td>0.568591</td>\n",
       "      <td>0.489645</td>\n",
       "      <td>0.421386</td>\n",
       "      <td>0.495461</td>\n",
       "      <td>0.492164</td>\n",
       "      <td>0.506459</td>\n",
       "      <td>0.520890</td>\n",
       "      <td>0.535680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_003_CA_1_validation</td>\n",
       "      <td>0.781506</td>\n",
       "      <td>0.682876</td>\n",
       "      <td>0.638148</td>\n",
       "      <td>0.696206</td>\n",
       "      <td>0.810679</td>\n",
       "      <td>0.571588</td>\n",
       "      <td>0.627279</td>\n",
       "      <td>1.006633</td>\n",
       "      <td>0.964254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865541</td>\n",
       "      <td>0.872323</td>\n",
       "      <td>0.961457</td>\n",
       "      <td>0.779914</td>\n",
       "      <td>0.674325</td>\n",
       "      <td>0.691499</td>\n",
       "      <td>0.735979</td>\n",
       "      <td>0.871511</td>\n",
       "      <td>0.939229</td>\n",
       "      <td>0.894397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_004_CA_1_validation</td>\n",
       "      <td>0.073571</td>\n",
       "      <td>0.058494</td>\n",
       "      <td>0.061651</td>\n",
       "      <td>0.066924</td>\n",
       "      <td>0.082225</td>\n",
       "      <td>0.034896</td>\n",
       "      <td>0.019261</td>\n",
       "      <td>0.271307</td>\n",
       "      <td>0.245482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268973</td>\n",
       "      <td>0.394013</td>\n",
       "      <td>0.356173</td>\n",
       "      <td>0.308006</td>\n",
       "      <td>0.344749</td>\n",
       "      <td>0.347902</td>\n",
       "      <td>0.359056</td>\n",
       "      <td>0.399084</td>\n",
       "      <td>0.478224</td>\n",
       "      <td>0.457925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_005_CA_1_validation</td>\n",
       "      <td>1.316392</td>\n",
       "      <td>1.233851</td>\n",
       "      <td>1.427181</td>\n",
       "      <td>1.387651</td>\n",
       "      <td>1.530134</td>\n",
       "      <td>1.060117</td>\n",
       "      <td>1.149283</td>\n",
       "      <td>1.194807</td>\n",
       "      <td>1.025809</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235766</td>\n",
       "      <td>1.412522</td>\n",
       "      <td>1.342656</td>\n",
       "      <td>1.062715</td>\n",
       "      <td>1.053345</td>\n",
       "      <td>0.997277</td>\n",
       "      <td>1.069564</td>\n",
       "      <td>1.312053</td>\n",
       "      <td>1.322963</td>\n",
       "      <td>1.397213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id        F1        F2        F3        F4  \\\n",
       "0  FOODS_1_001_CA_1_validation  0.750139  0.772505  0.771933  0.783363   \n",
       "1  FOODS_1_002_CA_1_validation  0.479268  0.430599  0.407865  0.411677   \n",
       "2  FOODS_1_003_CA_1_validation  0.781506  0.682876  0.638148  0.696206   \n",
       "3  FOODS_1_004_CA_1_validation  0.073571  0.058494  0.061651  0.066924   \n",
       "4  FOODS_1_005_CA_1_validation  1.316392  1.233851  1.427181  1.387651   \n",
       "\n",
       "         F5        F6        F7        F8        F9    ...          F19  \\\n",
       "0  0.942362  0.919770  1.248111  0.899572  0.786103    ...     1.031215   \n",
       "1  0.419198  0.259251  0.384414  0.392110  0.494740    ...     0.463434   \n",
       "2  0.810679  0.571588  0.627279  1.006633  0.964254    ...     0.865541   \n",
       "3  0.082225  0.034896  0.019261  0.271307  0.245482    ...     0.268973   \n",
       "4  1.530134  1.060117  1.149283  1.194807  1.025809    ...     1.235766   \n",
       "\n",
       "        F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0  1.129099  1.070506  0.760960  0.719134  0.720440  0.709261  0.935049   \n",
       "1  0.627420  0.568591  0.489645  0.421386  0.495461  0.492164  0.506459   \n",
       "2  0.872323  0.961457  0.779914  0.674325  0.691499  0.735979  0.871511   \n",
       "3  0.394013  0.356173  0.308006  0.344749  0.347902  0.359056  0.399084   \n",
       "4  1.412522  1.342656  1.062715  1.053345  0.997277  1.069564  1.312053   \n",
       "\n",
       "        F27       F28  \n",
       "0  1.028566  1.007027  \n",
       "1  0.520890  0.535680  \n",
       "2  0.939229  0.894397  \n",
       "3  0.478224  0.457925  \n",
       "4  1.322963  1.397213  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(f'result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
